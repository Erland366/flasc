{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study the simple setting\n",
    "\n",
    "finetune two models and merge; can also do it in the FL setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingyu/anaconda3/envs/flasc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-10 14:33:28.044275: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-10 14:33:28.063784: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from merging import MergingFactory\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import data_utils\n",
    "import torch\n",
    "from train_utils import get_metric\n",
    "from copy import deepcopy\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_distance(model1, model2):\n",
    "    distance = 0\n",
    "    for n, p in model1.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            distance += torch.sum((p - model2.state_dict()[n]) ** 2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x793f7d32b7d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class args:\n",
    "    dataset=\"20newsgroups\"\n",
    "    client_batch=16\n",
    "    clients=100\n",
    "    iid_alpha=0.1  # the lower, the more non-iid\n",
    "    seed=0\n",
    "    eval_frac=1.0\n",
    "    lora_rank=16\n",
    "    lora_alpha=16\n",
    "    freeze_a = \"false\"\n",
    "    merging_strategy = \"average\"\n",
    "    return_peft_model = False  # use peft model or just add adapters; for nvative peft merging\n",
    "    \n",
    "# set seed for debugging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import set_seed\n",
    "set_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "# torch.cuda.manual_seed_all(args.seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare models and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 2374656 parameters (1.91% of original 124455168)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingyu/anaconda3/envs/flasc/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clients, valloader, testloader, test_batch = data_utils.build_dataset(args.dataset,\n",
    "                                                                      args.client_batch,\n",
    "                                                                      args.clients,\n",
    "                                                                      args.iid_alpha, args.seed, args.eval_frac)\n",
    "\n",
    "import models\n",
    "model = models.build_model(args.dataset)\n",
    "total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "peft_model = models.add_adapters_dataset(args.dataset, model, args.lora_rank,\n",
    "                                args.lora_alpha, ft_output_layer=True,\n",
    "                                return_peft_model=args.return_peft_model)\n",
    "if args.return_peft_model:\n",
    "    model = peft_model\n",
    "    \n",
    "def str2bool(s):\n",
    "    return s.lower() == 'true'\n",
    "\n",
    "if str2bool(args.freeze_a):\n",
    "    for n,p in model.named_parameters():\n",
    "        if \"lora_A\" in n:\n",
    "            p.requires_grad = False\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Training {trainable} parameters ({100*trainable/total:.2f}% of original {total})\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_freeze = False\n",
    "server_lr = 1e-3 # for the original fedavg, this is one; for others like fedadam, we can set it to 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_model = model\n",
    "orig_server_model = deepcopy(server_model)  # backup if need\n",
    "\n",
    "server_params = {n:p for n,p in server_model.named_parameters() if p.requires_grad}\n",
    "server_mask = {n:torch.ones_like(p) for n,p in server_params.items()}\n",
    "server_freeze = False\n",
    "if server_freeze:\n",
    "    for p in server_params.values():\n",
    "        p.requires_grad = False\n",
    "\n",
    "from train_utils import Yogi\n",
    "# server_opt = torch.optim.SGD(server_params.values(), lr=server_lr)\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "server_opt = Yogi(server_params.values(), lr=server_lr,\n",
    "                    beta1=beta1, beta2=beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_strategy =  args.merging_strategy\n",
    "merger = MergingFactory.get_merging_strategy(merging_strategy, server_model, args=args)\n",
    "scaling_coefficient = 1.0  # no need to change\n",
    "\n",
    "eval_accu = 0\n",
    "def eval_loop(model, loader):\n",
    "    model.eval()\n",
    "    stats_acc = {}\n",
    "    for x,y in loader:\n",
    "        with torch.no_grad():\n",
    "            _, stats = test_batch(model, x, y)\n",
    "        for k,v in stats.items():\n",
    "            stats_acc[k] = stats_acc.get(k, 0) + v\n",
    "    stats_acc['loss'] /= stats_acc['count']\n",
    "    return stats_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_batch = 2  # how many clients we use\n",
    "client_lr = 1e-3\n",
    "\n",
    "# clients = [clients[0], clients[1]]  # we take out two loaders to use\n",
    "client_epochs = 6  # local training epochs; in standard FL setting, this is 1\n",
    "l2_clip_norm = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell only finetunes two models, without merging. A simple FL setup can be recovered by increasing the global rounds and adding the merging code in the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_distances = [[], []]\n",
    "between_distances = []\n",
    "checkpoints = [[], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 0, epoch 0 | loss 0.0962:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9514563106796117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 0, epoch 1 | loss 0.0831:   0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9805825242718447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 0, epoch 2 | loss 0.0073:   0%|          | 0/1 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 0, epoch 3 | loss 0.0031:   0%|          | 0/1 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 0, epoch 4 | loss 0.0006:   0%|          | 0/1 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 0, epoch 5 | loss 0.0001:   0%|          | 0/1 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 1, epoch 0 | loss 0.0387:   0%|          | 0/1 [00:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9518072289156626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 1, epoch 1 | loss 0.0033:   0%|          | 0/1 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 1, epoch 2 | loss 0.0046:   0%|          | 0/1 [00:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 1, epoch 3 | loss 0.0013:   0%|          | 0/1 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 1, epoch 4 | loss 0.0001:   0%|          | 0/1 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 1, epoch 5 | loss 0.0001:   0%|          | 0/1 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0 | client 1, epoch 5 | loss 0.0001: 100%|██████████| 1/1 [00:12<00:00, 12.39s/it]\n"
     ]
    }
   ],
   "source": [
    "merging_strategy = 'average'\n",
    "\n",
    "rounds = 1\n",
    "\n",
    "pbar = tqdm(range(rounds))\n",
    "\n",
    "# select two \n",
    "client_ids = [0, 1]\n",
    "client_loaders = [clients[i] for i in client_ids]\n",
    "\n",
    "# client_loaders = clients\n",
    "\n",
    "for round_idx, rnd in enumerate(pbar):\n",
    "    # # radomly select some\n",
    "    # client_ids = torch.randperm(len(clients))[:server_batch]\n",
    "    # client_loaders = [clients[i] for i in client_ids]\n",
    "\n",
    "    neg_client_deltas = []\n",
    "    stats_acc = {}\n",
    "    client_models = [deepcopy(server_model) for _ in range(len(client_ids))]\n",
    "    # for fisher_merging, regmean_merging, the weights will be normalized\n",
    "    # again in the merging function\n",
    "    # for ties_merging, currently the average_weights are not passed to the merging function;\n",
    "    # we can only change the scaling coefficient \n",
    "    average_weights = torch.Tensor([len(client_loader) for client_loader in client_loaders])\n",
    "    if merging_strategy in ['average', 'fisher_merging', 'regmean_merging']:\n",
    "        average_weights = average_weights / average_weights.sum()\n",
    "    elif merging_strategy in ['ties_merging', \"task_arthmetic\"]:\n",
    "        average_weights.fill_(1.0)  # use 1.0 for all clients, default option for now\n",
    "    nums_fisher_examples = torch.Tensor([(len(client_loader)-1)*client_loader.batch_size for client_loader in client_loaders])\n",
    "    nums_regmean_examples = nums_fisher_examples.clone()\n",
    "    # clients_this_round = server_batch  # record the number of clients for this round\n",
    "\n",
    "\n",
    "    for i, client_id in enumerate(client_ids):\n",
    "        # Download Model\n",
    "        client_model = client_models[i]\n",
    "        client_model.to(device)\n",
    "\n",
    "        # Local Training\n",
    "        # client_opt = torch.optim.SGD(client_model.parameters(), lr=client_lr, momentum=0.9)\n",
    "        client_opt = torch.optim.Adam(client_model.parameters(), lr=client_lr)\n",
    "        client_loader = clients[client_id]\n",
    "        client_acc = {}\n",
    "        \n",
    "        # use lr scheduler\n",
    "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(client_opt, T_max=client_epochs)\n",
    "        # scheduler = torch.optim.lr_scheduler.MultiStepLR(client_opt, milestones=[20], gamma=0.1)\n",
    "        \n",
    "        for epoch in range(client_epochs):\n",
    "            for x,y in client_loader:\n",
    "                loss, stats = test_batch(client_model, x, y)\n",
    "                \n",
    "                client_opt.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                if l2_clip_norm > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(client_model.parameters(), l2_clip_norm)\n",
    "\n",
    "                client_opt.step()\n",
    "                # scheduler.step()\n",
    "\n",
    "                for k,v in stats.items():\n",
    "                    client_acc[k] = client_acc.get(k, 0) + v\n",
    "                pbar.set_description(f\"eval: {eval_accu} | client {i}, epoch {epoch} | loss {loss:.4f}\")\n",
    "                \n",
    "            if epoch % 1 == 0:\n",
    "                eval_model = deepcopy(client_model)\n",
    "                eval_model.to(device)\n",
    "                eval_results = eval_loop(eval_model, client_loader)\n",
    "                print(\"Accuracy is {}\".format(get_metric(eval_results, \"accu\")))\n",
    "                # if epoch % 10 == 0:\n",
    "                #     # test OOD accuracy\n",
    "                #     # eval_results = eval_loop(eval_model, client_loaders[i^1])\n",
    "                #     # print(\"OOD Accuracy is {}\".format(get_metric(eval_results, \"accu\")))\n",
    "                #     # save models        \n",
    "                #     checkpoints[i].append(deepcopy(client_model).to(\"cpu\"))\n",
    "            \n",
    "            # record distance\n",
    "            ft_distances[i].append(get_distance(client_model.to(\"cpu\"), orig_server_model).item())\n",
    "            client_model.to(device)\n",
    "\n",
    "        # This is our delta parameter\n",
    "        client_model.to(\"cpu\")  # move to cpu to save memory\n",
    "        neg_client_delta = {\n",
    "            n: server_params[n].data - cp.data for n,cp \n",
    "                            in client_model.named_parameters() if cp.requires_grad\n",
    "        }\n",
    "        neg_client_deltas.append(neg_client_delta)\n",
    "\n",
    "        # Log last iteration\n",
    "        client_acc['norm'] = 0\n",
    "        for k,v in client_acc.items():\n",
    "            stats_acc[k] = stats_acc.get(k, 0) + v\n",
    "\n",
    "    # # merging\n",
    "    # average_weights = torch.Tensor([len(client_loader) for client_loader in client_loaders])\n",
    "    # if merging_strategy in ['average', 'fisher_merging', 'regmean_merging']:\n",
    "    #     average_weights = average_weights / average_weights.sum()\n",
    "    # elif merging_strategy in ['ties_merging', \"task_arthmetic\"]:\n",
    "    #     average_weights.fill_(1.0)  # use 1.0 for all clients, default option for now\n",
    "\n",
    "    # aggregated_update = merger.aggregate_updates(neg_client_deltas,\n",
    "    #                                                 average_weights=average_weights,  # for regeman/fisher we can use, e.g., torch.tensor([4, 1])\n",
    "    #                                                 scaling_coefficient=scaling_coefficient,\n",
    "    #                                                 client_loaders=client_loaders,\n",
    "    #                                                 test_batch=test_batch,\n",
    "    #                                                 nums_fisher_examples=nums_fisher_examples,\n",
    "    #                                                 nums_regmean_examples=nums_regmean_examples,\n",
    "    #                                                 device=device,\n",
    "    #                                                 normalize_fisher_weight=True,\n",
    "    #                                                 minimal_fisher_weight = 1e-6)\n",
    "    # merger.update_server_model(aggregated_update, server_opt)\n",
    "    # # evaluation\n",
    "    # eval_model = deepcopy(server_model)\n",
    "    # eval_model.to(device)\n",
    "\n",
    "    # print(f\"Evaluation for Round {round_idx}\")\n",
    "    # for client_loader in client_loaders:\n",
    "    #     eval_results = eval_loop(eval_model, client_loader)\n",
    "    #     print(get_metric(eval_results, \"accu\"))\n",
    "    \n",
    "    # eval_results = eval_loop(eval_model, valloader)\n",
    "    # print(f\"Evaluation for Round {round_idx}\")\n",
    "    # print(get_metric(eval_results, \"accu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0403,  0.0024,  0.0250,  ..., -0.0416,  0.0059, -0.0153],\n",
       "        [ 0.0382, -0.0182, -0.0390,  ...,  0.0248,  0.0239, -0.0067],\n",
       "        [ 0.0290,  0.0183,  0.0318,  ..., -0.0025, -0.0159,  0.0228],\n",
       "        ...,\n",
       "        [-0.0224, -0.0411,  0.0119,  ..., -0.0406, -0.0014, -0.0172],\n",
       "        [-0.0007, -0.0424, -0.0072,  ..., -0.0106,  0.0122, -0.0162],\n",
       "        [-0.0081,  0.0030,  0.0068,  ..., -0.0071,  0.0383,  0.0098]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_model.transformer.h[0].attn.c_attn.lora_A.default.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293.2576904296875\n",
      "346.666015625\n",
      "347.8883972167969\n",
      "348.7913818359375\n",
      "349.5709533691406\n",
      "331.12005615234375\n",
      "348.4221496582031\n",
      "350.11932373046875\n",
      "351.3020935058594\n",
      "352.3476867675781\n"
     ]
    }
   ],
   "source": [
    "for client_0, client_1 in zip(checkpoints[0], checkpoints[1]):\n",
    "    distance = get_distance(client_0, client_1).item()\n",
    "    print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Round 0\n",
      "0.6990291262135923\n",
      "0.060240963855421686\n"
     ]
    }
   ],
   "source": [
    "# server model\n",
    "cur_server_model = deepcopy(orig_server_model)\n",
    "cur_server_params = {n:p for n,p in cur_server_model.named_parameters() if p.requires_grad}\n",
    "cur_server_opt = Yogi(cur_server_params.values(), lr=server_lr,\n",
    "                    beta1=beta1, beta2=beta2)\n",
    "\n",
    "ckpt_idx = 5\n",
    "client_0, client_1 = checkpoints[0][ckpt_idx], checkpoints[1][ckpt_idx]\n",
    "\n",
    "cur_neg_client_deltas = []\n",
    "cur_neg_client_delta = {\n",
    "    n: cur_server_params[n].data - cp.data for n,cp \n",
    "                    in client_0.named_parameters() if cp.requires_grad\n",
    "}\n",
    "cur_neg_client_deltas.append(cur_neg_client_delta)\n",
    "cur_neg_client_delta = {\n",
    "    n: cur_server_params[n].data - cp.data for n,cp \n",
    "                    in client_1.named_parameters() if cp.requires_grad\n",
    "}\n",
    "cur_neg_client_deltas.append(cur_neg_client_delta)\n",
    "\n",
    "# merging\n",
    "merging_strategy = \"average\"\n",
    "average_weights = torch.Tensor([len(client_loader) for client_loader in client_loaders])\n",
    "if merging_strategy in ['average', 'fisher_merging', 'regmean_merging']:\n",
    "    average_weights = average_weights / average_weights.sum()\n",
    "elif merging_strategy in ['ties_merging', \"task_arthmetic\"]:\n",
    "    average_weights.fill_(1.0)  # use 1.0 for all clients, default option for now\n",
    "\n",
    "# average_weights = torch.tensor([1, 1.2])\n",
    "# average_weights = average_weights / average_weights.sum()\n",
    "# average_weights = torch.tensor([8, 1])\n",
    "# average_weights = average_weights ** 4\n",
    "\n",
    "merger = MergingFactory.get_merging_strategy(merging_strategy, cur_server_model, args=args)\n",
    "aggregated_update = merger.aggregate_updates(cur_neg_client_deltas,\n",
    "                                                average_weights=average_weights,  # for regeman/fisher we can use, e.g., torch.tensor([4, 1])\n",
    "                                                scaling_coefficient=scaling_coefficient,\n",
    "                                                client_loaders=client_loaders,\n",
    "                                                test_batch=test_batch,\n",
    "                                                nums_fisher_examples=nums_fisher_examples,\n",
    "                                                nums_regmean_examples=nums_regmean_examples,\n",
    "                                                device=device,\n",
    "                                                normalize_fisher_weight=True,\n",
    "                                                minimal_fisher_weight = 1e-6)\n",
    "merger.update_server_model(aggregated_update, cur_server_opt)\n",
    "# evaluation\n",
    "eval_model = deepcopy(cur_server_model)\n",
    "eval_model.to(device)\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[0])\n",
    "print(f\"Evaluation for Round {round_idx}\")\n",
    "print(get_metric(eval_results, \"accu\"))\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[1])\n",
    "print(get_metric(eval_results, \"accu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Round 0\n",
      "0.02912621359223301\n"
     ]
    }
   ],
   "source": [
    "eval_model = deepcopy(server_model)\n",
    "eval_model.to(device)\n",
    "eval_results = eval_loop(eval_model, client_loaders[0])\n",
    "print(f\"Evaluation for Round {round_idx}\")\n",
    "print(get_metric(eval_results, \"accu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x703ecd9b2ec0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ft_distances[0], label=\"Client 0\")\n",
    "plt.plot(ft_distances[1], label=\"Client 1\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Round 9\n",
      "0.9029126213592233\n",
      "0.9156626506024096\n",
      "0.8494623655913979\n",
      "0.6486486486486487\n",
      "0.8058252427184466\n",
      "0.7029702970297029\n"
     ]
    }
   ],
   "source": [
    "print(f\"Evaluation for Round {round_idx}\")\n",
    "for client_loader in client_loaders:\n",
    "    eval_results = eval_loop(eval_model, client_loader)\n",
    "    print(get_metric(eval_results, \"accu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_server_model = deepcopy(server_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yogi (\n",
       "Parameter Group 0\n",
       "    beta1: 0.9\n",
       "    beta2: 0.999\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_server_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Round 0\n",
      "0.5728155339805825\n",
      "0.21686746987951808\n"
     ]
    }
   ],
   "source": [
    "cur_server_model = deepcopy(server_model)  # orig_server_model\n",
    "cur_server_params = {n:p for n,p in cur_server_model.named_parameters() if p.requires_grad}\n",
    "cur_server_opt = Yogi(cur_server_params.values(), lr=server_lr,\n",
    "                    beta1=beta1, beta2=beta2)\n",
    "# cur_server_opt_sd = cur_server_opt.state_dict()\n",
    "# cur_server_opt_sd['state'] = deepcopy(server_opt.state_dict()['state'])\n",
    "# cur_server_opt.load_state_dict(cur_server_opt_sd)\n",
    "\n",
    "# merging\n",
    "merging_strategy = \"average\"\n",
    "average_weights = torch.Tensor([len(client_loader) for client_loader in client_loaders])\n",
    "if merging_strategy in ['average', 'fisher_merging', 'regmean_merging']:\n",
    "    average_weights = average_weights / average_weights.sum()\n",
    "elif merging_strategy in ['ties_merging', \"task_arthmetic\"]:\n",
    "    average_weights.fill_(1.0)  # use 1.0 for all clients, default option for now\n",
    "\n",
    "# average_weights = torch.tensor([1, 1.2])\n",
    "# average_weights = average_weights / average_weights.sum()\n",
    "# average_weights = torch.tensor([8, 1])\n",
    "# average_weights = average_weights ** 4\n",
    "\n",
    "merger = MergingFactory.get_merging_strategy(merging_strategy, cur_server_model, args=args)\n",
    "aggregated_update = merger.aggregate_updates(neg_client_deltas,\n",
    "                                                average_weights=average_weights,  # for regeman/fisher we can use, e.g., torch.tensor([4, 1])\n",
    "                                                scaling_coefficient=scaling_coefficient,\n",
    "                                                client_loaders=client_loaders,\n",
    "                                                test_batch=test_batch,\n",
    "                                                nums_fisher_examples=nums_fisher_examples,\n",
    "                                                nums_regmean_examples=nums_regmean_examples,\n",
    "                                                device=device,\n",
    "                                                normalize_fisher_weight=True,\n",
    "                                                minimal_fisher_weight = 1e-6)\n",
    "merger.update_server_model(aggregated_update, cur_server_opt)\n",
    "# evaluation\n",
    "eval_model = deepcopy(cur_server_model)\n",
    "eval_model.to(device)\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[0])\n",
    "print(f\"Evaluation for Round {round_idx}\")\n",
    "print(get_metric(eval_results, \"accu\"))\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[1])\n",
    "print(get_metric(eval_results, \"accu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Round 0\n",
      "0.8543689320388349\n"
     ]
    }
   ],
   "source": [
    "eval_model = deepcopy(cur_server_model)\n",
    "eval_model.to(device)\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[0])\n",
    "print(f\"Evaluation for Round {round_idx}\")\n",
    "print(get_metric(eval_results, \"accu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between client 0 and server model: 146.1201629638672\n",
      "Distance between client 1 and server model: 161.16949462890625\n"
     ]
    }
   ],
   "source": [
    "# calculate the distance between the client models and the server model=\n",
    "\n",
    "\n",
    "\n",
    "dist_0 = get_distance(client_models[0], orig_server_model)\n",
    "dist_1 = get_distance(client_models[1], orig_server_model)\n",
    "\n",
    "print(f\"Distance between client 0 and server model: {dist_0}\")\n",
    "print(f\"Distance between client 1 and server model: {dist_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(349.5710, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distance(client_models[0], client_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "# Distance between client 0 and server model: 8.39322280883789\n",
    "# Distance between client 1 and server model: 21.487966537475586\n",
    "\n",
    "# adam\n",
    "# Distance between client 0 and server model: 125.06092071533203\n",
    "# Distance between client 1 and server model: 126.78553009033203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Round 0\n",
      "0.02912621359223301\n"
     ]
    }
   ],
   "source": [
    "eval_model = deepcopy(orig_server_model)\n",
    "eval_model.to(device)\n",
    "eval_results = eval_loop(eval_model, client_loaders[0])\n",
    "print(f\"Evaluation for Round {round_idx}\")\n",
    "print(get_metric(eval_results, \"accu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the performances of the finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43037974683544306"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = deepcopy(client_models[0])\n",
    "eval_model.to(device)\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[0])\n",
    "\n",
    "get_metric(eval_results, \"accu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45348837209302323"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = deepcopy(client_models[1])\n",
    "eval_model.to(device)\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[1])\n",
    "\n",
    "get_metric(eval_results, \"accu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merging\n",
    "\n",
    "need to run them all everytime we try a new merging method, because we edit the `cur_server_model` in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the pretraiend model\n",
    "cur_server_model = deepcopy(orig_server_model)\n",
    "cur_server_params = {n:p for n,p in cur_server_model.named_parameters() if p.requires_grad}\n",
    "cur_server_opt = torch.optim.SGD(cur_server_params.values(), lr=server_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for merging\n",
    "merging_strategy = \"average\"\n",
    "merger = MergingFactory.get_merging_strategy(merging_strategy, cur_server_model, args=args)  # average, task_arithmetic, fisher_merging, ties_merging, regmean_merging\n",
    "scaling_coefficient = 1.  # controls how far we want to go in the direction of the aggregated task vector, only used in task arithmetic\n",
    "param_value_mask_rate = 0.5  # controls how much parameters we want to prune/drop in ties-merging (and dare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging\n",
    "average_weights = torch.Tensor([len(client_loader) for client_loader in client_loaders])\n",
    "if merging_strategy in ['average', 'fisher_merging', 'regmean_merging']:\n",
    "    average_weights = average_weights / average_weights.sum()\n",
    "elif merging_strategy in ['ties_merging', \"task_arthmetic\"]:\n",
    "    average_weights.fill_(1.0)  # use 1.0 for all clients, default option for now\n",
    "\n",
    "aggregated_update = merger.aggregate_updates(neg_client_deltas,\n",
    "                                                average_weights=average_weights,  # for regeman/fisher we can use, e.g., torch.tensor([4, 1])\n",
    "                                                scaling_coefficient=scaling_coefficient,\n",
    "                                                client_loaders=client_loaders,\n",
    "                                                test_batch=test_batch,\n",
    "                                                nums_fisher_examples=nums_fisher_examples,\n",
    "                                                nums_regmean_examples=nums_regmean_examples,\n",
    "                                                device=device,\n",
    "                                                normalize_fisher_weight=True,\n",
    "                                                minimal_fisher_weight = 1e-6,\n",
    "                                                param_value_mask_rate= param_value_mask_rate)\n",
    "merger.update_server_model(aggregated_update, cur_server_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28270042194092826\n",
      "0.01744186046511628\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "eval_model = deepcopy(cur_server_model)\n",
    "eval_model.to(device)\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[0])\n",
    "print(get_metric(eval_results, \"accu\"))\n",
    "\n",
    "eval_results = eval_loop(eval_model, client_loaders[1])\n",
    "print(get_metric(eval_results, \"accu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-weighted average\n",
    "# 0.620253164556962\n",
    "# 0.8953488372093024\n",
    "\n",
    "# weighted average\n",
    "# 0.9282700421940928\n",
    "# 0.563953488372093\n",
    "\n",
    "# non-weighted fisher\n",
    "# 0.0970464135021097\n",
    "# 1.0\n",
    "\n",
    "# non-weighted fisher\n",
    "# 0.1940928270042194\n",
    "# 0.9941860465116279\n",
    "\n",
    "# weighted fisher\n",
    "# 0.25316455696202533\n",
    "# 0.9883720930232558\n",
    "\n",
    "# weighted regmean\n",
    "# 0.8016877637130801\n",
    "# 0.9593023255813954\n",
    "\n",
    "# non-weighted ties \n",
    "# 0.70042194092827\n",
    "# 0.38953488372093026\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flasc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
