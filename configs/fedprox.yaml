gpu: "0"
dir: "runs"
name: "fedprox_experiment"
save: "true"
dataset: "20newsgroups"
iid-alpha: 0.1
clients: 100
model: "gpt2"
seed: 0

# Evaluation settings
eval-freq: 10
eval-first: "false"
eval-frac: 1.0
eval-masked: "true"

# Server settings
server-opt: "adam"
server-lr: 1.0e-3
server-batch: 10
server-rounds: 100
server-freeze: "false"
server-hparams:
  beta1: 0.9
  beta2: 0.999

# Client settings
client-lr: 1.0e-3
client-batch: 16
client-epochs: 1
client-freeze: "false"

# LoRA settings
freeze-a: "false"
lora-rank: 16
lora-alpha: 16

# Privacy settings
l2-clip-norm: 0.0
noise-multiplier: 0.0

# Logging settings
use_wandb: true
use_tensorboard: true
project_name: "federated_merging"
entity: null

# Merging strategy
merging_strategy: "fedprox"
merging_kwargs:
  mu: 0.01